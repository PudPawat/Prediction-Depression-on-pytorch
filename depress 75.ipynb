{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Networks   \n",
    "    \n",
    "num_neuron = 10\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    # define nn\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.fc1 = nn.Linear(71, num_neuron)      \n",
    "        self.fc5 = nn.Linear(num_neuron, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "        X = self.fc1(X)\n",
    "        X = self.fc5(X)\n",
    "        X = self.softmax(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surveyid</th>\n",
       "      <th>village</th>\n",
       "      <th>survey_date</th>\n",
       "      <th>femaleres</th>\n",
       "      <th>age</th>\n",
       "      <th>married</th>\n",
       "      <th>children</th>\n",
       "      <th>hhsize</th>\n",
       "      <th>edu</th>\n",
       "      <th>hh_children</th>\n",
       "      <th>...</th>\n",
       "      <th>given_mpesa</th>\n",
       "      <th>amount_given_mpesa</th>\n",
       "      <th>received_mpesa</th>\n",
       "      <th>amount_received_mpesa</th>\n",
       "      <th>net_mpesa</th>\n",
       "      <th>saved_mpesa</th>\n",
       "      <th>amount_saved_mpesa</th>\n",
       "      <th>early_survey</th>\n",
       "      <th>depressed</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>679</td>\n",
       "      <td>50</td>\n",
       "      <td>11-Dec-61</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>667</td>\n",
       "      <td>95</td>\n",
       "      <td>26-Sep-61</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1160</td>\n",
       "      <td>192</td>\n",
       "      <td>23-Oct-61</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>419</td>\n",
       "      <td>22</td>\n",
       "      <td>27-Apr-60</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>217</td>\n",
       "      <td>9</td>\n",
       "      <td>19-May-60</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   surveyid  village survey_date  femaleres   age  married  children  hhsize  \\\n",
       "0       679       50   11-Dec-61          1  55.0        1         4       6   \n",
       "1       667       95   26-Sep-61          1  17.0        1         2       3   \n",
       "2      1160      192   23-Oct-61          1  25.0        1         3       5   \n",
       "3       419       22   27-Apr-60          1  47.0        1         1       3   \n",
       "4       217        9   19-May-60          1  28.0        0         2       3   \n",
       "\n",
       "   edu  hh_children  ...  given_mpesa  amount_given_mpesa  received_mpesa  \\\n",
       "0    1            0  ...            0                 0.0               0   \n",
       "1    8            0  ...            0                 0.0               0   \n",
       "2    9            3  ...            0                 0.0               0   \n",
       "3   12            1  ...            0                 0.0               0   \n",
       "4   10            2  ...            0                 0.0               0   \n",
       "\n",
       "   amount_received_mpesa  net_mpesa  saved_mpesa  amount_saved_mpesa  \\\n",
       "0                    0.0        0.0            1                 0.0   \n",
       "1                    0.0        0.0            0                 0.0   \n",
       "2                    0.0        0.0            0                 0.0   \n",
       "3                    0.0        0.0            0                 0.0   \n",
       "4                    0.0        0.0            0                 0.0   \n",
       "\n",
       "   early_survey  depressed  day_of_week  \n",
       "0             0          0            2  \n",
       "1             0          0            3  \n",
       "2             0          0            2  \n",
       "3             1          0            4  \n",
       "4             1          0            5  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "PATH = 'depression_new_del600'\n",
    "dataset = pd.read_csv('dataset/75/'+PATH+'.csv')\n",
    "dataset.shape\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Xdata = dataset.drop(['surveyid','survey_date', 'village','depressed'],axis = 1)\n",
    "ydata = dataset[['depressed']]\n",
    "\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(Xdata.values,\n",
    "                                                    dataset.depressed.values)\n",
    "\n",
    "#torch.from_numpy(train_X)\n",
    "# wrap up with Variable in pytorch\n",
    "train_X = Variable(torch.Tensor(train_X).float())\n",
    "test_X = Variable(torch.Tensor(test_X).float())\n",
    "\n",
    "train_y = Variable(torch.Tensor(train_y).long())\n",
    "test_y = Variable(torch.Tensor(test_y).long())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epoch 0 loss tensor(0.8200)\n",
      "number of epoch 100 loss tensor(0.6236)\n",
      "number of epoch 200 loss tensor(0.6191)\n",
      "number of epoch 300 loss tensor(0.6160)\n",
      "number of epoch 400 loss tensor(0.6142)\n",
      "number of epoch 500 loss tensor(0.6131)\n",
      "number of epoch 600 loss tensor(0.6122)\n",
      "number of epoch 700 loss tensor(0.6116)\n",
      "number of epoch 800 loss tensor(0.6105)\n",
      "number of epoch 900 loss tensor(0.6100)\n",
      "number of epoch 1000 loss tensor(0.6094)\n",
      "number of epoch 1100 loss tensor(0.6087)\n",
      "number of epoch 1200 loss tensor(0.6085)\n",
      "number of epoch 1300 loss tensor(0.6079)\n",
      "number of epoch 1400 loss tensor(0.6081)\n",
      "number of epoch 1500 loss tensor(0.6073)\n",
      "number of epoch 1600 loss tensor(0.6075)\n",
      "number of epoch 1700 loss tensor(0.6070)\n",
      "number of epoch 1800 loss tensor(0.6066)\n",
      "number of epoch 1900 loss tensor(0.6066)\n",
      "number of epoch 2000 loss tensor(0.6063)\n",
      "number of epoch 2100 loss tensor(0.6066)\n",
      "number of epoch 2200 loss tensor(0.6061)\n",
      "number of epoch 2300 loss tensor(0.6058)\n",
      "number of epoch 2400 loss tensor(0.6057)\n",
      "number of epoch 2500 loss tensor(0.6056)\n",
      "number of epoch 2600 loss tensor(0.6057)\n",
      "number of epoch 2700 loss tensor(0.6058)\n",
      "number of epoch 2800 loss tensor(0.6053)\n",
      "number of epoch 2900 loss tensor(0.6056)\n",
      "number of epoch 3000 loss tensor(0.6051)\n",
      "number of epoch 3100 loss tensor(0.6052)\n",
      "number of epoch 3200 loss tensor(0.6053)\n",
      "number of epoch 3300 loss tensor(0.6053)\n",
      "number of epoch 3400 loss tensor(0.6052)\n",
      "number of epoch 3500 loss tensor(0.6051)\n",
      "number of epoch 3600 loss tensor(0.6048)\n",
      "number of epoch 3700 loss tensor(0.6047)\n",
      "number of epoch 3800 loss tensor(0.6054)\n",
      "number of epoch 3900 loss tensor(0.6047)\n",
      "number of epoch 4000 loss tensor(0.6045)\n",
      "number of epoch 4100 loss tensor(0.6050)\n",
      "number of epoch 4200 loss tensor(0.6047)\n",
      "number of epoch 4300 loss tensor(0.6045)\n",
      "number of epoch 4400 loss tensor(0.6044)\n",
      "number of epoch 4500 loss tensor(0.6052)\n",
      "number of epoch 4600 loss tensor(0.6043)\n",
      "number of epoch 4700 loss tensor(0.6044)\n",
      "number of epoch 4800 loss tensor(0.6047)\n",
      "number of epoch 4900 loss tensor(0.6131)\n",
      "prediction accuracy 0.6029411764705882\n",
      "macro precision 0.53125\n",
      "micro precision 0.6029411764705882\n",
      "macro recall 0.5137362637362638\n",
      "micro recall 0.6029411764705882\n",
      "precision 0.4375\n",
      "recall 0.1346153846153846\n"
     ]
    }
   ],
   "source": [
    "net = Net2()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()# cross entropy loss\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "loss_app = []\n",
    "\n",
    "for epoch in range(5000):\n",
    "    optimizer.zero_grad()\n",
    "    #train_X, train_y = train_X.to(device), train_y.to(device)\n",
    "    out = net(train_X)\n",
    "    #print(out)\n",
    "    loss = criterion(out, train_y)\n",
    "    \n",
    "    #print(loss)\n",
    "    loss.backward()\n",
    "    #print(loss.backward())\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('number of epoch', epoch, 'loss', loss.data)\n",
    "        loss_app.append(loss.detach().numpy())\n",
    "        \n",
    "#test_X,test_y =         \n",
    "predict_out = net(test_X)\n",
    "_, predict_y = torch.max(predict_out, 1)\n",
    "\n",
    "print('prediction accuracy', accuracy_score(test_y.data, predict_y.data))\n",
    "\n",
    "print('macro precision', precision_score(test_y.data, predict_y.data, average='macro'))\n",
    "print('micro precision', precision_score(test_y.data, predict_y.data, average='micro'))\n",
    "print('macro recall', recall_score(test_y.data, predict_y.data, average='macro'))\n",
    "print('micro recall', recall_score(test_y.data, predict_y.data, average='micro'))\n",
    "\n",
    "print('precision', precision_score(test_y.data, predict_y.data,average='binary'))\n",
    "\n",
    "print('recall', recall_score(test_y.data, predict_y.data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[75., 45.],\n",
      "        [ 9.,  7.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\w\\b\\windows\\pytorch\\aten\\src\\ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.\n",
      "C:\\w\\b\\windows\\pytorch\\aten\\src\\ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0\n",
      "TP 75.0, TN 7.0, FP 45.0, FN 9.0\n",
      "Sensitivity = 0.8928571343421936\n",
      "Specificity = 0.13461539149284363\n"
     ]
    }
   ],
   "source": [
    "out = net(test_X)\n",
    "\n",
    "def confusion_matrix(preds, labels):\n",
    "\n",
    "    preds = torch.argmax(preds, 1)\n",
    "    conf_matrix = torch.zeros(2, 2)\n",
    "    for p, t in zip(preds, labels):\n",
    "        conf_matrix[p, t] += 1\n",
    "\n",
    "    print(conf_matrix)\n",
    "    TP = conf_matrix.diag()\n",
    "    for c in range(1):\n",
    "        idx = torch.ones(2).byte()\n",
    "        idx[c] = 0\n",
    "        TN = conf_matrix[idx.nonzero()[:,None], idx.nonzero()].sum()\n",
    "        FP = conf_matrix[c, idx].sum()\n",
    "        FN = conf_matrix[idx, c].sum()\n",
    "\n",
    "        sensitivity = (TP[c] / (TP[c]+FN))\n",
    "        specificity = (TN / (TN+FP))\n",
    "\n",
    "        print('Class {}\\nTP {}, TN {}, FP {}, FN {}'.format(\n",
    "            c, TP[c], TN, FP, FN))\n",
    "        print('Sensitivity = {}'.format(sensitivity))\n",
    "        print('Specificity = {}'.format(specificity))\n",
    "    return  TP[c], TN, FP, FN\n",
    "\n",
    "\n",
    "\n",
    "TP,TN,FP,FN = confusion_matrix(out, test_y)\n",
    "TP,TN,FP,FN = int(TP),int(TN),int(FP),int(FN)\n",
    "\n",
    "numpy_loss_history = np.array(loss_app)\n",
    "#print(numpy_loss_history)\n",
    "\n",
    "np.savetxt(\"Data = \"+PATH +\",   No.neuron=\"+ str(num_neuron)+\", acc\"+str(acc*100)+\", TP=\"+ str(TP)+\", TN=\"+str(TN)+\", FP=\"+str(FP) + \", FN=\"+str(FN)+\", loss inside\"+\".txt\",numpy_loss_history,delimiter=\",\")\n",
    "#save for collect data and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
